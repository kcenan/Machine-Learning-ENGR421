{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to show result of multilayer perceptron classification\n",
    "\n",
    "Dataset contains 1000 clothing images \\of size 28 pixels Ã— 28 pixels\n",
    "I aim to detect type of clothings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 :\n",
    "#### read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesdf = pd.read_csv('hw03_images.csv',header=None)\n",
    "labeldf = pd.read_csv('hw03_labels.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_v = pd.read_csv('initial_V.csv',header=None)\n",
    "initial_w = pd.read_csv('initial_W.csv',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 :\n",
    "\n",
    "#### Divide data into 2 part which are test set and train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = imagesdf.iloc[0:500]\n",
    "test_x = imagesdf.iloc[-500:]\n",
    "train_y = labeldf.iloc[0:500]\n",
    "test_y = labeldf.iloc[-500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    return 1/(1+np.exp(-X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.005 \n",
    "epsilon = 1e-3 \n",
    "H = 20 #number of hidden nodes\n",
    "max_iteration = 500 #max number of iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### z : hidden node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.insert(loc = 0, value = 1,column=784)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = sigmoid(train_x.dot(initial_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.insert(loc = 0, value = 1,column=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0 = sigmoid(z.dot(initial_v)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####z0 is all close to 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_head = z0.copy() #initial y_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_values = -sum(train_y * np.log(y_head) + (1 - train_y) * np.log(1 - y_head)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "random = [[i] for i in range(500)]\n",
    "shuffle(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = initial_w.copy()\n",
    "v = initial_v.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 1\n",
    "while(1):\n",
    "    for i in random :\n",
    "        i = i[0]\n",
    "        # calculate hidden nodes\n",
    "        current_X = train_x[i:]\n",
    "      \n",
    "        \n",
    "        z.iloc[:,i:] = sigmoid(current_X.iloc[:,1:].dot(W))\n",
    "        # calculate output node\n",
    "        current_z = z[i:]\n",
    "        y_head[i:] = sigmoid(current_z.dot(v))\n",
    "\n",
    "        delta_v = eta * (train_y.loc[:i,:]- y_head.loc[:i,:] ) * current_z\n",
    "        delta_W = eta * (train_y.loc[1,:i] - y_head.loc[:i,:]) * current_X.iloc[1,:i].dot((v.iloc[2:(H + 1),1].transpose() )* z.loc[i, 1:H] * (1 - z[i, 1:H]))\n",
    "        \n",
    "        v = v + delta_v\n",
    "        W = W + delta_W\n",
    "  \n",
    "\n",
    "    z = sigmoid(train_x.insert(loc = 0, value = 1,column=len(train_x)).dot(W))\n",
    "    y_predicted = sigmoid(z.insert(loc = 0, value = 1,column=len(train_x)).dot(v))\n",
    "    objective_values = objective_values.append(-sum(train_y * np.log(y_predicted) + (1 - y_head) * np.log(1 - y_predicted)))\n",
    "  \n",
    "    if (abs(objective_values[iteration + 1] - objective_values[iteration]) < epsilon | iteration >= max_iteration) :\n",
    "        break\n",
    "  \n",
    "  \n",
    "    iteration = iteration + 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
